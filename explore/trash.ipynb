{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c20864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add check for cycles involving duplicated blocks that are getting ignored here\n",
    "def all_paths_from_matrix(edge_matrix, start_idx, end_idx):\n",
    "    \"\"\"\n",
    "    Return all simple paths from start_idx to end_idx.\n",
    "    Duplicated blocks leading to circles are usually not causing a problem because they are small insertions that have many low count edges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_matrix : array-like (n x n)\n",
    "        Adjacency matrix. Nonzero = edge (weight kept as attribute 'weight').\n",
    "    start_idx, end_idx : int\n",
    "        Node indices (rows/cols of the matrix).\n",
    "    \"\"\"\n",
    "\n",
    "    G = nx.from_numpy_array(edge_matrix, create_using=nx.DiGraph)\n",
    "\n",
    "    paths_gen = nx.all_simple_paths(G, source=start_idx, target=end_idx)\n",
    "    paths = [list(p) for p in paths_gen]\n",
    "    return paths\n",
    "\n",
    "all_paths = all_paths_from_matrix(edge_matrix, start_node, end_node)\n",
    "\n",
    "# TODO: do I need a flow limit on combined paths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e935822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_or_make_dedup_idx(variant: tuple[int, int | None], variant_to_dedup_idx, dedup_idx_to_variant) -> int:\n",
    "    if variant not in variant_to_dedup_idx:\n",
    "        didx = len(variant_to_dedup_idx)\n",
    "        variant_to_dedup_idx[variant] = didx\n",
    "        dedup_idx_to_variant[didx] = variant\n",
    "    return variant_to_dedup_idx[variant]\n",
    "\n",
    "def deduplicate_paths(blockstats_df, paths_blocks):\n",
    "\n",
    "    duplicated_ids = set(blockstats_df[blockstats_df['duplicated'] == True].index)\n",
    "\n",
    "    variant_to_dedup_idx: dict[tuple[int, int | None], int] = {}   # (block_id, left_context_block_id_or_None) -> dedup_idx\n",
    "    dedup_idx_to_variant: dict[int, tuple[int, int | None]] = {}   # inverse map\n",
    "\n",
    "    deduplicated_paths = {}\n",
    "\n",
    "\n",
    "    for isolate, path in paths_blocks.items():\n",
    "        encoded_path = []\n",
    "        last_non_duplicated = None\n",
    "        for block in path:\n",
    "            if block in duplicated_ids:\n",
    "                variant_block = (block, last_non_duplicated)\n",
    "            else:\n",
    "                variant_block = (block, None)\n",
    "                last_non_duplicated = block\n",
    "            encoded_path.append(_get_or_make_dedup_idx(variant_block, variant_to_dedup_idx, dedup_idx_to_variant))\n",
    "        deduplicated_paths[isolate] = encoded_path\n",
    "\n",
    "    return deduplicated_paths, variant_to_dedup_idx, dedup_idx_to_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_junction_pangraph(pan: pp.Pangraph, add_consensus: bool = False, consensus_paths: list = None, order=\"tree\"):\n",
    "\n",
    "    if order == \"tree\":\n",
    "        leaf_order = get_tree_order()\n",
    "\n",
    "    path_dict = pan.to_path_dictionary()\n",
    "    bdf = pan.to_blockstats_df()\n",
    "    n_core = bdf[\"core\"].sum()\n",
    "    n_acc = len(bdf) - n_core\n",
    "    cgen_acc = iter(sns.color_palette(\"rainbow\", n_acc))\n",
    "    cgen_core = iter(sns.color_palette(\"pastel\", n_core))\n",
    "    block_colors = {}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, len(path_dict) * 0.2))\n",
    "    y = 0\n",
    "    y_labels = []\n",
    "\n",
    "    for name in leaf_order:\n",
    "        if name not in pan.paths:\n",
    "            continue\n",
    "        path = pan.paths[name]\n",
    "        for node_id in path.nodes:\n",
    "            block, strand, start, end = pan.nodes[node_id][\n",
    "                [\"block_id\", \"strand\", \"start\", \"end\"]\n",
    "            ]\n",
    "            if block not in block_colors:\n",
    "                if bdf.loc[block, \"core\"]:\n",
    "                    color = next(cgen_core)\n",
    "                else:\n",
    "                    color = next(cgen_acc)\n",
    "                block_colors[block] = color\n",
    "            else:\n",
    "                color = block_colors[block]\n",
    "            block_len = bdf.loc[block, \"len\"]\n",
    "            edgecolor = \"black\" if strand else \"red\"\n",
    "            ax.barh(\n",
    "                y,\n",
    "                width=end - start,\n",
    "                left=start,\n",
    "                color=color,\n",
    "                edgecolor=edgecolor,\n",
    "            )\n",
    "        y_labels.append(name)\n",
    "        y += 1\n",
    "\n",
    "    if add_consensus:\n",
    "        for i, cons_path in enumerate(consensus_paths):\n",
    "            start = 0\n",
    "            for block_id in cons_path:\n",
    "                block_len = bdf.loc[block_id, \"len\"]\n",
    "                ax.barh(\n",
    "                    y,\n",
    "                    width=block_len,\n",
    "                    left=start,\n",
    "                    color=block_colors[block_id],\n",
    "                    edgecolor=\"black\", # TODO: potentially consider block orientation in consensus\n",
    "                )\n",
    "                start += block_len\n",
    "            y_labels.append(f\"consensus_{i+1}\")\n",
    "            y += 1\n",
    "            \n",
    "\n",
    "    ax.set_yticks(range(len(y_labels)), y_labels)\n",
    "    ax.set_xlabel(\"genomic position (bp)\")\n",
    "    #ax.set_title(f\"Junction graph for edge {selected_edge}\")\n",
    "    ax.grid(axis=\"x\", alpha=0.4)\n",
    "    ax.set_ylim(-1, len(y_labels))\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "def build_edge_matrix(paths: dict, block_names: list):\n",
    "    \"\"\"\n",
    "    Builds a NumPy edge matrix (NxN) counting how often each directed edge occurs.\n",
    "    Currently adds inversed blocks as if they were not inversed.\n",
    "    \n",
    "    Args:\n",
    "        paths: dict[str, list[int]] – for each path, the list of node IDs\n",
    "        block_names: list[int] – all node IDs in the desired order\n",
    "\n",
    "    Returns:\n",
    "        edge_matrix: np.ndarray of shape (N, N)\n",
    "    \"\"\"\n",
    "    n = len(block_names)\n",
    "    edge_matrix = np.zeros((n, n), dtype=int)\n",
    "    block_to_idx = {node: i for i, node in enumerate(block_names)}\n",
    "    idx_to_block = {v: k for k, v in block_to_idx.items()}\n",
    "    \n",
    "    for seq in paths.values():\n",
    "        for a, b in zip(seq, seq[1:]):\n",
    "            i, j = block_to_idx[a], block_to_idx[b]\n",
    "            edge_matrix[i, j] += 1\n",
    "\n",
    "    return edge_matrix, block_to_idx, idx_to_block\n",
    "\n",
    "def remove_duplicated_blocks(bs_df, edge_matrix, block_to_idx):\n",
    "    dupl_indices = []\n",
    "    for dupl_block in bs_df[bs_df['duplicated'] == True].index:\n",
    "        dupl_indices.append(block_to_idx[dupl_block])\n",
    "\n",
    "    edge_matrix[dupl_indices,:] = 0\n",
    "    edge_matrix[:,dupl_indices] = 0\n",
    "\n",
    "    return edge_matrix\n",
    "\n",
    "def remove_duplicated_blocks_early(blockstats_df, path_dict):\n",
    "    duplicated_blocks = set(blockstats_df[blockstats_df['duplicated'] == True].index)\n",
    "\n",
    "    filtered_data = {\n",
    "        name: [bid for bid, _ in lst if bid not in duplicated_blocks]\n",
    "        for name, lst in path_dict.items()\n",
    "    }\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def filter_rare_blocks(blockstats_df, paths_blocks, rare_threshold):\n",
    "    rare_blocks = set(blockstats_df.loc[blockstats_df['count'] < rare_threshold].index)\n",
    "\n",
    "    filtered_data = {\n",
    "        key: [bid for bid in bids if bid not in rare_blocks]\n",
    "        for key, bids in paths_blocks.items()\n",
    "    }\n",
    "    return filtered_data\n",
    "\n",
    "def all_paths_from_matrix(edge_matrix, start_idx, end_idx):\n",
    "    \"\"\"\n",
    "    Return all simple paths from start_idx to end_idx.\n",
    "    Duplicated blocks leading to circles are usually not causing a problem because they are small insertions that have many low count edges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_matrix : array-like (n x n)\n",
    "        Adjacency matrix. Nonzero = edge (weight kept as attribute 'weight').\n",
    "    start_idx, end_idx : int\n",
    "        Node indices (rows/cols of the matrix).\n",
    "    \"\"\"\n",
    "\n",
    "    G = ig.Graph.Adjacency(edge_matrix)\n",
    "\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ig.plot(G, target=ax)  # uses matplotlib instead of cairo\n",
    "    #plt.show()\n",
    "\n",
    "    paths = G.get_all_simple_paths(v=start_idx, to=end_idx, mode = 'out')\n",
    "    return paths\n",
    "\n",
    "# TODO: do I need a flow limit on combined paths?\n",
    "# TODO: should I have a cycle check on paths?\n",
    "\n",
    "def transform_path_indices_to_block_ids(paths, idx_to_block):\n",
    "    transformed_paths = []\n",
    "    for path in paths:\n",
    "        block_path = [idx_to_block[idx] for idx in path]\n",
    "        transformed_paths.append(block_path)\n",
    "    return transformed_paths\n",
    "\n",
    "def transform_block_ids_to_path_indices(paths, block_to_idx):\n",
    "    transformed_paths = []\n",
    "    for path in paths:\n",
    "        block_path = [block_to_idx[block] for block in path]\n",
    "        transformed_paths.append(block_path)\n",
    "    return transformed_paths\n",
    "\n",
    "def remove_paths_with_rare_edges(paths_blocks, edge_matrix, block_to_idx, flow_threshold = 10):\n",
    "\n",
    "    unique_paths = set()\n",
    "\n",
    "    for isolate, path in paths_blocks.items():\n",
    "        # TODO: potentially extend to order isolates to paths, need to find a way what to do with removed paths\n",
    "        is_valid_path = True\n",
    "        for idx in range(len(path)-1):\n",
    "            first_block = block_to_idx[path[idx]]\n",
    "            second_block = block_to_idx[path[idx+1]]\n",
    "            if edge_matrix[first_block, second_block] < flow_threshold:\n",
    "                is_valid_path = False\n",
    "                break\n",
    "        if is_valid_path:\n",
    "            unique_paths.add(tuple(path))\n",
    "\n",
    "    unique_paths = [list(p) for p in unique_paths]\n",
    "    print(f\"Found {len(unique_paths)} unique paths.\")\n",
    "\n",
    "    return unique_paths\n",
    "\n",
    "def get_consensus_paths(pangraph, flow_threshold=7, remove_duplicates = False, filter_rare = False, rare_threshold = 5):\n",
    "    path_dict = pangraph.to_path_dictionary()\n",
    "\n",
    "    # sort blocks by overall frequency (TODO: do I still need this?)\n",
    "    blockstats_df = pangraph.to_blockstats_df()\n",
    "    block_order = blockstats_df.sort_values(\"count\", ascending=True).index.to_list()\n",
    "    \n",
    "    if remove_duplicates:\n",
    "        paths_blocks = remove_duplicated_blocks_early(blockstats_df, path_dict)\n",
    "    else:\n",
    "        paths_blocks = {name: [bid for bid, _ in lst] for name, lst in path_dict.items()}\n",
    "\n",
    "    if filter_rare:\n",
    "        paths_blocks = filter_rare_blocks(blockstats_df, paths_blocks, rare_threshold=rare_threshold)\n",
    "    \n",
    "    edge_matrix, block_to_idx, idx_to_block = build_edge_matrix(paths_blocks, block_order)\n",
    "    #edge_matrix[np.where(edge_matrix<flow_threshold)] = 0\n",
    "\n",
    "    #if remove_duplicates:\n",
    "    #    edge_matrix = remove_duplicated_blocks(blockstats_df, edge_matrix, block_to_idx)\n",
    "\n",
    "    #first_path = next(iter(paths_blocks))\n",
    "    #start_node = block_to_idx[paths_blocks[first_path][0]]\n",
    "    #end_node = block_to_idx[paths_blocks[first_path][-1]]\n",
    "\n",
    "    #all_paths = all_paths_from_matrix(edge_matrix, start_node, end_node)\n",
    "    #all_paths_ids = transform_path_indices_to_block_ids(all_paths, idx_to_block)\n",
    "    all_paths_ids = remove_paths_with_rare_edges(paths_blocks, edge_matrix, block_to_idx, flow_threshold)\n",
    "    all_paths = transform_block_ids_to_path_indices(all_paths_ids, block_to_idx)\n",
    "\n",
    "    return all_paths, all_paths_ids, edge_matrix\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
